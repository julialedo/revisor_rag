import google.generativeai as genai
import os
import textwrap
from typing import Optional
from dotenv import load_dotenv
# -----------------------------------------------------------
# I. CHAVES E CONFIGURA√á√ïES (Do seu c√≥digo anexo)
# -----------------------------------------------------------
load_dotenv() # Carrega as vari√°veis do arquivo .env localmente

# ‚ùå REMOVA A CHAVE EM TEXTO CLARO AQUI!
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

try:
    genai.configure(api_key=GEMINI_API_KEY)
    # Definindo o modelo como no seu notebook
    model = genai.GenerativeModel('gemini-2.0-flash')
except Exception as e:
    print(f"‚ùå ERRO: Falha ao configurar a API do Gemini. Verifique sua API_KEY. Erro: {e}")
    model = None


# -----------------------------------------------------------
# II. FUN√á√ÉO DE CLASSIFICA√á√ÉO (Adaptada do seu c√≥digo anexo)
# -----------------------------------------------------------

def classificar_texto(texto: str) -> Optional[str]:
    """
    Classifica textos relacionados ao agroneg√≥cio em PRODUTO, CULTURA ou OUTROS,
    usando a l√≥gica e prompt fornecidos.
    """
    if not model:
        print("‚ùå MODELO INDISPON√çVEL. N√£o √© poss√≠vel classificar.")
        return None

    prompt = f"""Analise o texto/arquivo/diret√≥rio abaixo e classifique-o em UMA das categorias:

CATEGORIAS:
1. PRODUTO: Se refere a qualquer produto/servi√ßo para venda ou uso agr√≠cola.
   - Nomes comerciais de produtos (ORONDIS¬Æ, POLYTRIN, Miravis Pro, Yieldon, Seeker)
   - Argument√°rios de vendas, apresenta√ß√µes t√©cnicas de produtos
   - Folhetos comerciais, fichas t√©cnicas promocionais
   - Exemplos do que pode surgir: "Argument√°rio de vendas ORONDIS¬Æ", "Apresenta√ß√£o T√©cnica Curyom"

2. CULTURA: Se foca especificamente em uma cultura agr√≠cola ou planta√ß√£o.
   - Soja, milho, arroz, trigo, caf√©, algod√£o, cana, feij√£o
   - Culturas espec√≠ficas mencionadas no t√≠tulo/conte√∫do principal
   - Exemplos: "Manejo de soja", "Doen√ßas do milho", "Cultivo de trigo"

3. OUTROS: Se for um documento t√©cnico, manual, livro, artigo, guia, publica√ß√£o cient√≠fica.
   - Manuais t√©cnicos, livros acad√™micos
   - Artigos cient√≠ficos, publica√ß√µes de pesquisa
   - Guias de boas pr√°ticas, procedimentos
   - Materiais educacionais, apresenta√ß√µes acad√™micas
   - Normas, regulamentos, editais
   - Exemplos: "Manual de Identifica√ß√£o de Plantas Daninhas", "Fisiologia vegetal",
     "Livro Manejo de Nematoides", "Manual de boas pr√°ticas"

Texto para classificar: "{texto}"

REGRA IMPORTANTE:
1. Retorne APENAS: "produto", "cultura" ou "outros"
2. Responda com apenas uma palavra e em capslook: PRODUTO, CULTURA OU OUTROS."""

    try:
        # Gerar resposta do Gemini
        response = model.generate_content(prompt)

        # Extrair e limpar a resposta
        resposta = response.text.strip().upper()
        print(f"DEBUG: Resposta bruta do LLM: {resposta}")
        
        # Sua l√≥gica de valida√ß√£o do notebook (que transforma a sa√≠da)
        if "PRODUTO" in resposta:
            return "PRODUTO"
        elif "CULTURA" in resposta:
            return "CULTURA"
        elif "OUTROS" in resposta:
            return "OUTROS"
        else:
            return f"CLASSIFICA√á√ÉO N√ÉO RECONHECIDA: {resposta}"

    except Exception as e:
        return f"ERRO ao classificar: {str(e)}"
    


import requests
import json
from typing import List, Dict
import os
from dotenv import load_dotenv


# -----------------------------------------------------------
# I. CHAVES E CONFIGURA√á√ïES DO ASTRA DB
# -----------------------------------------------------------

# Chaves Astra DB (adaptadas do seu notebook anexo)




load_dotenv() # Carrega as vari√°veis do arquivo .env localmente

ASTRA_DB_APPLICATION_TOKEN = os.getenv("ASTRA_DB_APPLICATION_TOKEN")
ASTRA_DB_API_ENDPOINT = os.getenv("ASTRA_DB_API_ENDPOINT")
ASTRA_DB_NAMESPACE = os.getenv("ASTRA_DB_NAMESPACE")
# -----------------------------------------------------------
# II. CLASSE AstraDBClient (Do seu c√≥digo anexo)
# -----------------------------------------------------------

class AstraDBClient:
    """Classe wrapper para a conex√£o e busca no Astra DB."""
    def __init__(self):
        self.base_url = f"{ASTRA_DB_API_ENDPOINT}/api/json/v1/{ASTRA_DB_NAMESPACE}"
        self.headers = {
            "Content-Type": "application/json",
            "x-cassandra-token": ASTRA_DB_APPLICATION_TOKEN,
            "Accept": "application/json"
        }
        print("‚úÖ AstraDBClient inicializado.")
        
    def vector_search(self, collection: str, vector: List[float], limit: int = 6) -> List[Dict]:
        """Realiza busca por similaridade vetorial na cole√ß√£o especificada."""
        if not collection or collection == "ERRO":
            print("‚ùå Busca vetorial abortada: Cole√ß√£o inv√°lida ou erro na classifica√ß√£o.")
            return []
            
        url = f"{self.base_url}/{collection}" 
        payload = {
            "find": {
                "sort": {"$vector": vector},
                "options": {"limit": limit}
            }
        }
        
        print(f"\n--- Chamando Astra DB na Cole√ß√£o: {collection} ---")
        try:
            response = requests.post(url, json=payload, headers=self.headers, timeout=30)
            response.raise_for_status() 
            data = response.json()
            
            documents = data.get("data", {}).get("documents", [])
            print(f"‚úÖ Busca realizada. Documentos retornados: {len(documents)}")
            return documents

        except requests.exceptions.HTTPError as e:
            print(f"‚ùå ERRO HTTP na busca Astra DB (Status: {response.status_code}): {e}")
            return []
        except Exception as e:
            print(f"‚ùå ERRO Geral na busca Astra DB: {str(e)}")
            return []

astra_client = AstraDBClient()



import openai
import os
import json
import hashlib
from typing import List, Dict, Optional
from dotenv import load_dotenv



load_dotenv() # Carrega as vari√°veis do arquivo .env localmente

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Define a chave de ambiente para o cliente OpenAI
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
if not OPENAI_API_KEY:
    print("‚ùå ATEN√á√ÉO: OPENAI_API_KEY n√£o est√° definida.")

# -----------------------------------------------------------
# II. CLASSE LLMClient (Para gerar a corre√ß√£o)
# -----------------------------------------------------------

class LLMClient:
    """Classe wrapper para o cliente de Chat Completion da OpenAI, simulando 'generate_content'."""
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        # Inicializa o cliente OpenAI
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        print(f"‚úÖ LLMClient inicializado com modelo: {self.model}")

    def generate_content(self, prompt: str) -> str:
        """M√©todo que simula a interface generate_content."""
        print("\n--- Chamando OpenAI Chat Completion ---")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um agente de revis√£o t√©cnica altamente preciso."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
        except openai.APIError as e:
            print(f"‚ùå ERRO NA GERA√á√ÉO DO LLM (API Error): {e}")
            return f"ERRO NA GERA√á√ÉO DO LLM (API Error): {str(e)}"
        except Exception as e:
            print(f"‚ùå ERRO NA GERA√á√ÉO DO LLM (Geral): {e}")
            return f"ERRO NA GERA√á√ÉO DO LLM (Geral): {str(e)}"

# Inicializa o cliente
modelo_texto = LLMClient(api_key=OPENAI_API_KEY)


# -----------------------------------------------------------
# III. FUN√á√ÉO get_embedding (Para a busca vetorial)
# -----------------------------------------------------------

def get_embedding(text: str) -> List[float]:
    """Obt√©m embedding do texto usando OpenAI com diagn√≥stico (adaptado do seu doc)."""
    print("\n--- Chamando OpenAI Embedding ---")
    try:
        # Usa o cliente j√° inicializado para embeddings
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.embeddings.create(
            input=text,
            model="text-embedding-3-small"
        )
        embedding = response.data[0].embedding

        # --- DIAGN√ìSTICO ---
        print(f"‚úÖ Embedding Gerado. Dimens√µes: {len(embedding)}. Primeiro valor: {embedding[0]:.6f}")
        # --- FIM DIAGN√ìSTICO ---

        return embedding
    except Exception as e:
        print(f"‚ùå ERRO na API OpenAI para Embedding: {str(e)}. Verifique se a chave est√° ativa.")
        # Seu fallback de hash foi removido, pois ele falha na busca RAG e queremos testar a conex√£o real.
        return []



def reescrever_revisor(content: str, colecao_override: Optional[str] = None) -> str:
    """
    Fun√ß√£o principal que executa o pipeline RAG completo.
    Atua como um Revisor T√©cnico, corrigindo imprecis√µes e enriquecendo o texto.
    Aceita colecao_override para sobrepor a classifica√ß√£o do Gemini.
    """
    
    colecao = None
    
    if colecao_override and colecao_override != "Autom√°tica (Classifica√ß√£o Gemini)":
        # 1a. Usa a cole√ß√£o fornecida pelo usu√°rio
        colecao = colecao_override
        print(f"\n--- 1. COLE√á√ÉO DEFINIDA PELO USU√ÅRIO: {colecao} ---")
    else:
        # 1b. Executa a classifica√ß√£o normal do Gemini
        print("\n--- 1. CLASSIFICA√á√ÉO AUTOM√ÅTICA (Gemini) ---")
        colecao = classificar_texto(content)
        print(f"Cole√ß√£o Identificada: {colecao}")
    
    if colecao in ["ERRO", "CLASSIFICA√á√ÉO N√ÉO RECONHECIDA:", None]:
        # Retorna a mensagem de erro como string, conforme solicitado.
        return f"Erro na classifica√ß√£o/sele√ß√£o da cole√ß√£o. Classifica√ß√£o falhou com: {colecao if colecao else 'ERRO'}. N√£o foi poss√≠vel iniciar a busca RAG."

    # 2. EMBEDDING E BUSCA
    embedding = get_embedding(content[:800])
    
    if not embedding or len(embedding) < 1536:
        return "Erro fatal na gera√ß√£o do Embedding. Verifique sua chave OpenAI ativa. N√£o foi poss√≠vel buscar no Astra DB."
        
    relevant_docs = astra_client.vector_search(colecao, embedding, limit=10)
    print(f"2. Busca Vetorial conclu√≠da na cole√ß√£o '{colecao}'. Documentos retornados: {len(relevant_docs)}")
    
    # 3. CONSTR√ìI CONTEXTO RAG
    rag_context = ""
    if relevant_docs:
        rag_context = "### REFERENCIAL TE√ìRICO BUSCADO (RAG) ###\n"
        for i, doc in enumerate(relevant_docs, 1):
            doc_content = str(doc)
            doc_clean = doc_content.replace('{', '').replace('}', '').replace("'", "").replace('"', '')
            rag_context += f"--- Fonte {i} ---\n{doc_clean[:500]}...\n"
    else:
        rag_context = "Referencial te√≥rico n√£o retornou resultados espec√≠ficos relevantes."
    
    # 4. PROMPT DE GERA√á√ÉO AUMENTADA (Mantendo o prompt anterior, mas removendo a 'instrucao_incremental')
    final_prompt = f"""
    Voc√™ √© um **Revisor T√©cnico S√™nior** com foco na √°rea agr√≠cola, rigoroso, preciso e com a miss√£o de garantir a **veracidade cient√≠fica absoluta** do texto de entrada.
    Confira se os valores est√£o id√™nticos ao banco de dados.

    Seu objetivo √©:
    1. **CORRIGIR** automaticamente qualquer imprecis√£o, erro t√©cnico ou erro cient√≠fico no texto original.
    2. **ENRICHECER** o texto original, substituindo termos vagos por **terminologia t√©cnica precisa** (ex: troque 'veneno' por 'defensivo agr√≠cola' ou 'fitossanit√°rio').
    3. **ACRESCENTAR** dados concretos, n√∫meros e informa√ß√µes espec√≠ficas, *apenas* quando o **REFERENCIAL TE√ìRICO** fornecido for relevante para enriquecer ou corrigir o t√≥pico do texto original.
    4. **MANTER** a estrutura e o tamanho do texto original (m√°ximo delta de 5%).
    5. **PROIBIDO** adicionar informa√ß√µes que tangenciem ou desviem do tema central do texto original.

    ---
    ### TEXTO ORIGINAL A SER REVISADO ###
    {content}
    
    ---
    {rag_context}
    ---

    ## ESTRUTURA DE RETORNO OBRIGAT√ìRIA:

    Retorne o **TEXTO COMPLETAMENTE REVISADO E CORRIGIDO** primeiro.
    
    Ap√≥s, coloque quais dados foram buscados no banco de dados para essa corre√ß√£o.

    Em seguida, adicione uma subse√ß√£o chamada "üõ†Ô∏è Ajustes T√©cnicos e Corre√ß√µes" listando de forma concisa cada altera√ß√£o significativa feita (corre√ß√£o ou enriquecimento) e qual fonte foi usada.
    """

    # 5. Gera√ß√£o Final do LLM
    response_text = modelo_texto.generate_content(final_prompt)
        
    return response_text





# -----------------------------------------------------------
# V. FUN√á√ÉO ajuste_incremental (Para ajustes p√≥s-revis√£o)
# -----------------------------------------------------------
# -----------------------------------------------------------
# V. FUN√á√ÉO ajuste_incremental (Para ajustes p√≥s-revis√£o)
# -----------------------------------------------------------

def ajuste_incremental(texto_revisado: str, instrucao_incremental: str) -> str:
    """
    Aplica uma instru√ß√£o incremental ao texto j√° revisado (sa√≠da do reescrever_revisor).
    Mant√©m o formato e adiciona as mudan√ßas solicitadas.
    """
    if not instrucao_incremental:
        return texto_revisado # Retorna o texto original se n√£o houver instru√ß√£o

    print("\n--- INICIANDO AJUSTE INCREMENTAL ---")
    
    # 1. TENTA ISOLAR APENAS O TEXTO PRINCIPAL DA SA√çDA RAG
    # Isso √© crucial para evitar que o LLM inclua as se√ß√µes de metadados (Ajustes T√©cnicos) na resposta
    partes = texto_revisado.split("üõ†Ô∏è Ajustes T√©cnicos e Corre√ß√µes")
    texto_principal_rag = partes[0].strip()
    
    # PROMPT DE AJUSTE INCREMENTAL REFINADO
    final_prompt = f"""
    Voc√™ √© um **Editor S√™nior** com a √∫nica miss√£o de aplicar uma mudan√ßa incremental de forma fluida.
    
    Seu objetivo principal √© editar o TEXTO PRINCIPAL A SER AJUSTADO:
    1. **APENAS** edite o texto para incorporar as informa√ß√µes da INSTRU√á√ÉO INCREMENTAL de forma natural, **mantendo o tom t√©cnico**.
    2. N√£o √© para mencionar a instru√ß√£o incremental na sa√≠da.
    3. **PROIBIDO** manter ou incluir as se√ß√µes de metadados ("üõ†Ô∏è Ajustes T√©cnicos e Corre√ß√µes", "Dados Buscados", etc.) na sua resposta.

    ---
    ### TEXTO PRINCIPAL A SER AJUSTADO ###
    {texto_principal_rag}
    
    ---
    ### INSTRU√á√ÉO INCREMENTAL A SER ACRESCENTADA ###
    {instrucao_incremental}

    ---
    
    Retorne **SOMENTE O TEXTO FINAL RESULTANTE**, completamente editado e pronto.
    """

    try:
        # Usa o cliente LLM para gerar o conte√∫do
        response_text = modelo_texto.generate_content(final_prompt)
        print("‚úÖ Ajuste Incremental conclu√≠do.")
        return response_text
    except Exception as e:
        print(f"‚ùå ERRO na Gera√ß√£o do Ajuste Incremental: {str(e)}")
        return texto_revisado # Fallback para o texto original se falhar
    




import streamlit as st

# --- Configura√ß√µes da P√°gina ---
st.set_page_config(
    page_title="Corretor de Texto ",
    layout="wide"
)

# --- T√≠tulo e Status Inicial ---
st.title("üõ†Ô∏è Corretor de Texto ")
# üö® Descri√ß√£o do fluxo atualizada para refletir as duas etapas
st.markdown("**Fluxo de Duas Etapas:** 1. Revis√£o RAG (Classifica√ß√£o/Busca) ‚û°Ô∏è 2. Ajuste Incremental (Se houver)")
st.markdown("---")

# --- Verifica√ß√£o de Status da Chave OpenAI ---
# Nota: A fun√ß√£o get_embedding n√£o √© ideal para check, mas mantida para compatibilidade com o revisor.py
if not get_embedding("teste"):
    st.error("‚ùå ERRO CR√çTICO: Chave OpenAI INATIVA. A busca RAG falhar√°. Por favor, corrija a chave no 'revisor.py'.")
else:
    st.success("‚úÖ Conex√£o OpenAI OK. Pronto para rodar o RAG.")
st.markdown("---")

# --- Vari√°veis de Estado (Simples) ---
if 'saida_final' not in st.session_state:
    st.session_state.saida_final = ""
if 'ajustes_tecnicos' not in st.session_state:
    st.session_state.ajustes_tecnicos = "Nenhum ajuste t√©cnico realizado."
if 'colecao_usada' not in st.session_state:
    st.session_state.colecao_usada = "N/A"

# --- FUN√á√ÉO AUXILIAR PARA PARSEAR A SA√çDA DO RAG ---
# Como reescrever_revisor retorna uma string √∫nica, precisamos extrair o texto final e os ajustes.
def parse_rag_output(full_response: str, colecao: str) -> dict:
    if "Erro na classifica√ß√£o" in full_response or "Erro fatal na gera√ß√£o do Embedding" in full_response:
        return {
            "texto_final": full_response,
            "ajustes_tecnicos": "Falha na Etapa RAG.",
            "colecao_usada": colecao
        }

    # Tenta separar o texto principal dos ajustes t√©cnicos
    partes = full_response.split("üõ†Ô∏è Ajustes T√©cnicos e Corre√ß√µes")
    texto_final = partes[0].strip() if partes else full_response
    ajustes_tecnicos = partes[1].strip() if len(partes) > 1 else "N√£o foi poss√≠vel extrair a se√ß√£o de Ajustes T√©cnicos."
        
    return {
        "texto_final": texto_final,
        "ajustes_tecnicos": ajustes_tecnicos,
        "colecao_usada": colecao
    }


# --- 1. Se√ß√£o de Entradas ---
st.header("Entradas do Usu√°rio")

col1, col2 = st.columns(2)

with col1:
    texto_base = st.text_area(
        label="Texto Base para Revis√£o:",
        height=250, 
        placeholder="Insira o texto original aqui.",
    )

with col2:
    # Seletor Opcional de Cole√ß√£o
    colecoes_disponiveis = [
        "Autom√°tica (Classifica√ß√£o Gemini)", # Op√ß√£o padr√£o
        "PRODUTO",
        "CULTURA",
        "OUTROS"
    ]
    colecao_selecionada = st.selectbox(
        label="Escolha Opcional da Cole√ß√£o Astra DB:",
        options=colecoes_disponiveis,
        index=0, # Inicia na op√ß√£o autom√°tica
        help="Selecione uma cole√ß√£o espec√≠fica para busca RAG. Se 'Autom√°tica' for escolhida, a classifica√ß√£o Gemini ser√° usada."
    )
    
    instrucao_incremental = st.text_area(
        label="Instru√ß√£o Adicional/Incremental (Opcional):",
        height=150,
        placeholder="Ex: 'Mude o tom para formal' ou 'Aumente o segundo par√°grafo em 30 palavras'."
    )
    
# --- L√≥gica de Execu√ß√£o ---

st.markdown("---")

if st.button("Aplicar Corre√ß√£o", type="primary"):
    
    if not texto_base:
        st.warning("Por favor, insira um Texto Base para revis√£o.")
    else:
        # Inicializa o resultado final com o texto base em caso de falha
        final_text = texto_base

        # ----------------------------------------------------
        # üü¢ PASSO 1: REVIS√ÉO RAG (reescrever_revisor)
        # ----------------------------------------------------
        with st.spinner(f"1/2 Processando RAG na cole√ß√£o: {colecao_selecionada}..."):
            # CHAMA A FUN√á√ÉO CENTRAL DO RAG
            rag_output_str = reescrever_revisor(texto_base, colecao_override=colecao_selecionada)
            
            # PARSEA A SA√çDA PARA SEPARAR O TEXTO FINAL E OS AJUSTES
            resultado_rag_parse = parse_rag_output(rag_output_str, colecao_selecionada)
            
            st.session_state.ajustes_tecnicos = resultado_rag_parse["ajustes_tecnicos"]
            st.session_state.colecao_usada = resultado_rag_parse["colecao_usada"]
            final_text = resultado_rag_parse["texto_final"]
            
            if "Erro" in final_text:
                st.error(f"‚ùå Erro na Etapa RAG: {final_text}")
            else:
                st.success(f"‚úÖ Etapa 1 (RAG) Conclu√≠da. Cole√ß√£o utilizada: {st.session_state.colecao_usada}")

        # ----------------------------------------------------
        # üü† PASSO 2: AJUSTE INCREMENTAL (ajuste_incremental)
        # ----------------------------------------------------
        if instrucao_incremental and "Erro" not in final_text:
            with st.spinner("2/2 Aplicando Ajuste Incremental..."):
                final_text = ajuste_incremental(final_text, instrucao_incremental)
            
            st.success("‚ú® Ajuste Incremental Aplicado.")
            st.session_state.ajustes_tecnicos += "\n\n--- AJUSTE INCREMENTAL ---\nInstru√ß√£o Adicional Aplicada."
        elif instrucao_incremental and "Erro" in final_text:
             st.warning("Instru√ß√£o incremental ignorada devido a um erro na etapa RAG.")


        # ----------------------------------------------------
        # üèÅ ATUALIZA√á√ÉO FINAL
        # ----------------------------------------------------
        st.session_state.saida_final = final_text

st.markdown("---")

# --- 2. Se√ß√£o de Sa√≠da (Resultado Final) ---
st.header("Resultado Final")

# O resultado principal (texto limpo + dados buscados)
st.text_area(
    label="Texto Corrigido/Final (Resultado do RAG + Ajuste Incremental, se houver):",
    value=st.session_state.saida_final,
    height=450,
    disabled=True 
)

# A se√ß√£o de ajustes t√©cnicos e fontes (detalhes do RAG)
st.subheader("üõ†Ô∏è Detalhes da Revis√£o")
st.code(
    f"Cole√ß√£o RAG Utilizada: {st.session_state.colecao_usada}\n\n" + st.session_state.ajustes_tecnicos,
    language='markdown'
)
